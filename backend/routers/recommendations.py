from fastapi import APIRouter, Depends, HTTPException
from typing import Dict, Any
from sqlalchemy.orm import Session
from lib.database import get_db
from lib.models import User
from models.base_model import recommend_from_text

router = APIRouter()

@router.get("/recommend/{user_id}")
def recommend(user_id: int, db: Session = Depends(get_db)) -> Dict[str, Any]:
    """
    Returns job recommendations for the given user_id using the trained content-based model.
    """
    # 1. Fetch User from DB
    user = db.query(User).filter(User.id == user_id).first()
    if not user:
        raise HTTPException(status_code=404, detail="User not found")

    # 2. Construct Profile Text (similar to training pipeline)
    # "gender {Gender}, age {AgeBucket}, major {Major}, interested domain {InterestedDomain}, projects {Projects}, skills python {PythonSkill}, sql {SqlSkill}, java {JavaSkill}."
    
    # Helper for age bucket
    age_bucket = "under35"
    if user.age and user.age >= 35:
        age_bucket = "35plus"
    
    # Helper for projects list
    projects_str = ""
    if user.projects:
        if isinstance(user.projects, list):
            projects_str = " ".join(user.projects)
        else:
            projects_str = str(user.projects)

    profile_text = (
        f"gender {user.gender or 'Unknown'}, "
        f"age {age_bucket}, "
        f"interested domain {user.interested_domain or 'Unknown'}, "
        f"projects {projects_str}, "
        f"skills python {user.python_level or 'Weak'}, "
        f"sql {user.sql_level or 'Weak'}, "
        f"java {user.java_level or 'Weak'}."
    )
    
    print(f"[INFO] Generating recommendations for User {user_id} with profile: {profile_text[:100]}...")

    # 2.5 Get Seen Jobs (Likes and Passes)
    from lib.models import Interaction
    interactions = db.query(Interaction).filter(
        Interaction.user_id == user_id,
        Interaction.type == "job"
    ).all()
    seen_ids = [i.item_id for i in interactions]
    
    print(f"[INFO] User {user_id} has seen {len(seen_ids)} jobs. Excluding them.")

    # 3. Get Recommendations from Model
    # Check if we have a stored embedding (from online learning)
    limit = 10 # Batch size
    
    if user.profile_embedding:
        import torch
        from models.base_model import recommend_from_embedding
        print(f"[INFO] Using stored profile embedding for User {user_id}")
        u_emb = torch.tensor(user.profile_embedding)
        recommended_jobs = recommend_from_embedding(u_emb, top_k=limit, exclude_ids=seen_ids)
    else:
        # Fallback to text-based
        recommended_jobs, u_emb = recommend_from_text(profile_text, top_k=limit, exclude_ids=seen_ids)
        
        # Save this initial embedding to DB so we can update it later!
        if u_emb is not None:
            try:
                user.profile_embedding = u_emb.tolist()
                db.commit()
                print(f"[INFO] Initial profile embedding saved for User {user_id}")
            except Exception as e:
                print(f"[WARN] Could not save initial embedding: {e}")
    
    print(f"[INFO] Generated {len(recommended_jobs)} recommendations for User {user_id}")


    response = {
        "user_id": user_id,
        "num_recommendations": len(recommended_jobs),
        "recommendations": recommended_jobs,
        "note": "Generated by Content-Based Model (SentenceTransformer)",
    }
    return response
